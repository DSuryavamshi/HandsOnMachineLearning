{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No visualising data in this code. Just an end to end script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_data = pd.read_csv(f\"{os.getcwd()}{os.sep}housing.csv\")\n",
    "\n",
    "housing_data[\"median_income_cat\"] = pd.cut(\n",
    "    housing_data[\"median_income\"],\n",
    "    bins=[0.0, 1.5, 3.0, 4.5, 6.0, np.inf],\n",
    "    labels=[1, 2, 3, 4, 5],\n",
    ")\n",
    "\n",
    "strat_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_idx, test_idx in strat_split.split(housing_data, housing_data[\"median_income_cat\"]):\n",
    "    train_data_set  = housing_data.loc[train_idx]\n",
    "    test_data_set   = housing_data.loc[test_idx]\n",
    "\n",
    "for _ in (train_data_set, test_data_set):\n",
    "    _.drop('median_income_cat', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data_set.drop([\"median_house_value\"], axis=1)\n",
    "y_train = train_data_set[\"median_house_value\"].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms_idx, bedrooms_idx, population_idx, household_idx = 3, 4, 5, 6\n",
    "\n",
    "\n",
    "class CombineAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room=True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_idx] / X[:, household_idx]\n",
    "        population_per_household = X[:, population_idx] / X[:, household_idx]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_idx] / X[:, rooms_idx]\n",
    "            return np.c_[\n",
    "                X, rooms_per_household, population_per_household, bedrooms_per_room\n",
    "            ]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"attributes_adder\", CombineAttributesAdder()),\n",
    "        (\"std_scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "numerical_attributes = X_train.drop([\"ocean_proximity\"], axis=1).columns.tolist()\n",
    "catergorical_attributes = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer(\n",
    "    [\n",
    "        (\"numerical\", numerical_pipeline, numerical_attributes),\n",
    "        (\"categorical\", OneHotEncoder(), catergorical_attributes),\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepared = full_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [ 85657.90192014 305492.60737488 152056.46122456 186095.70946094\n",
      " 244550.67966089]\n",
      "Labels: [72100.0, 279600.0, 82700.0, 112500.0, 238300.0]\n"
     ]
    }
   ],
   "source": [
    "some_data = X_train.iloc[:5]\n",
    "some_labels = y_train.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "print(\"Predictions:\", lin_reg.predict(some_data_prepared))\n",
    "print(\"Labels:\", list(some_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68627.87390018745"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_predictions = lin_reg.predict(X_train_prepared)\n",
    "lin_mse = mean_squared_error(y_train, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_predictions = tree_reg.predict(X_train_prepared)\n",
    "tree_mse = mean_squared_error(y_train, housing_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks like zero error. but it means that the model has over fit the training set. Which is not good for our model, let's try using cross_val_score function, which will split the training data into ***k*** subsets and runs the model for ***k*** times. Then we can compare the socres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(\n",
    "    tree_reg, X_train_prepared, y_train, scoring=\"neg_mean_squared_error\", cv=10\n",
    ")\n",
    "tree_rmse_scores = np.sqrt(-scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [73553.24356399 70776.63314137 68620.34438505 70816.00217939\n",
      " 68968.92164705 76459.10750583 71204.42474235 73563.21406627\n",
      " 68633.5453335  71825.98907021]\n",
      "Mean: 71442.14256350111\n",
      "Standard deviation: 2390.230460089131\n"
     ]
    }
   ],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Now we see that the error for this model is greater than that of Linear Regression, let's try the same for liner regression model and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [71762.76364394 64114.99166359 67771.17124356 68635.19072082\n",
      " 66846.14089488 72528.03725385 73997.08050233 68802.33629334\n",
      " 66443.28836884 70139.79923956]\n",
      "Mean: 69104.07998247063\n",
      "Standard deviation: 2880.3282098180657\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(\n",
    "    lin_reg, X_train_prepared, y_train, scoring=\"neg_mean_squared_error\", cv=10\n",
    ")\n",
    "lin_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Compared to DecisionTreeRegressor, This is looking better. But still, a $69104 variation is not a good fit. Let's try a different model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18644.177904618315"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_predictions = forest_reg.predict(X_train_prepared)\n",
    "forest_mse = mean_squared_error(y_train, housing_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [51180.50530925 48712.60499157 46985.71589931 52301.2630304\n",
      " 47559.7530078  51957.81566893 52726.67468378 49547.1461688\n",
      " 48447.15547374 53894.68245356]\n",
      "Mean: 50331.33166871456\n",
      "Standard deviation: 2265.8872138206484\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(\n",
    "    forest_reg, X_train_prepared, y_train, scoring=\"neg_mean_squared_error\", cv=10\n",
    ")\n",
    "forest_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    This is not the best, but this is much better! You can save this model using joblib module and use it for different data. And now we can check the output on test result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read up on Grid Search, you have not completed that Yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1df7d80bc47f7e05a50e2eeaa18ffc0f7d22c2fa267186711acfade866193f8a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('machinelearning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
